import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os
import json
import pickle
import io
import time
from openai import OpenAI

# =========================================================
# ğŸ”‘ 0. è¯»å– API Key
# =========================================================
KEY_FILE = "api_key_config.txt"
API_KEY = None

if os.path.exists(KEY_FILE):
    with open(KEY_FILE, "r", encoding="utf-8") as f:
        API_KEY = f.read().strip()

# =========================================================
# ğŸ› ï¸ 1. è®¾ç½®ä¸èµ„æºåŠ è½½
# =========================================================
st.set_page_config(page_title="PlantAI Pro", page_icon="ğŸŒ¿", layout="wide")

# ğŸ¨ ä¼˜åŒ–åçš„ CSS (ä¿®å¤ Markdown æ¸²æŸ“æ ·å¼)
st.markdown("""
<style>
    /* éšè—é¡¶éƒ¨é»˜è®¤ Header */
    header {visibility: hidden;}

    /* ä¸»æ ‡é¢˜ */
    .main-title { 
        font-size: 2.5rem; 
        color: #2E7D32; 
        text-align: center; 
        font-weight: 800; 
        margin-bottom: 20px; 
    }

    /* ç»“æœå¡ç‰‡ */
    .result-card { 
        background: white; 
        padding: 25px; 
        border-radius: 12px; 
        box-shadow: 0 4px 15px rgba(0,0,0,0.08); 
        border-left: 6px solid #2E7D32; 
        margin-bottom: 20px; 
    }

    /* è¯†åˆ«ç»“æœæ–‡å­— */
    .latin-name { 
        font-size: 1.8rem; 
        font-weight: bold; 
        color: #1b1b1b; 
        font-family: 'Times New Roman', serif; 
        font-style: italic; 
    }

    /* ä¾§è¾¹æ èƒŒæ™¯ */
    section[data-testid="stSidebar"] { background-color: #f8f9fa; }

    /* ğŸ“ ä¿®å¤ Markdown æŠ¥å‘Šçš„æ ·å¼ */
    .report-container h2 {
        color: #2E7D32;
        font-size: 1.5rem;
        border-bottom: 2px solid #E8F5E9;
        padding-bottom: 8px;
        margin-top: 20px;
    }
    .report-container h3 {
        color: #388E3C;
        font-size: 1.2rem;
        margin-top: 15px;
    }
    .report-container strong {
        color: #1b5e20;
    }
    .report-container ul {
        margin-left: 20px;
    }
</style>
""", unsafe_allow_html=True)

# è·¯å¾„é…ç½®
WEIGHTS_PATH = 'data.pkl'
SPECIES_NAME_JSON = 'plantnet300K_species_id_2_name.json'
CLASS_TO_ID_JSON = 'class_idx_to_species_id.json'
NUM_CLASSES = 1081
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


@st.cache_resource
def load_resources():
    if not os.path.exists(SPECIES_NAME_JSON) or not os.path.exists(CLASS_TO_ID_JSON):
        st.error("âŒ ç¼ºå°‘ JSON æ–‡ä»¶")
        return None, None

    with open(CLASS_TO_ID_JSON, 'r', encoding='utf-8') as f:
        class_to_id = json.load(f)
    with open(SPECIES_NAME_JSON, 'r', encoding='utf-8') as f:
        species_id_to_name = json.load(f)

    class_names = []
    for i in range(NUM_CLASSES):
        species_id = str(class_to_id[str(i)])
        class_names.append(species_id_to_name.get(species_id, f"Unknown {species_id}"))

    if not os.path.exists(WEIGHTS_PATH):
        st.error(f"âŒ ç¼ºå°‘æƒé‡: {WEIGHTS_PATH}")
        return None, None

    base_dir = os.path.dirname(os.path.abspath(WEIGHTS_PATH))
    data_dir = os.path.join(base_dir, 'data')

    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)

    class CustomUnpickler(pickle.Unpickler):
        def find_class(self, module, name):
            if module == 'torch.storage' and name == '_load_from_bytes':
                return lambda b: torch.load(io.BytesIO(b), map_location='cpu', weights_only=False)
            return super().find_class(module, name)

        def persistent_load(self, saved_id):
            if isinstance(saved_id, tuple) and saved_id[0] == 'storage':
                typename, key, _, numel = saved_id[1], saved_id[2], saved_id[3], saved_id[4]
                typename_str = typename.__name__ if isinstance(typename, type) else str(typename)
                storage_cls = torch.FloatStorage
                if 'LongStorage' in typename_str:
                    storage_cls = torch.LongStorage
                elif 'IntStorage' in typename_str:
                    storage_cls = torch.IntStorage
                data_file_path = os.path.join(data_dir, str(key))
                return storage_cls.from_file(data_file_path, shared=False, size=numel)
            return saved_id

    try:
        with open(WEIGHTS_PATH, 'rb') as f:
            checkpoint = CustomUnpickler(f).load()
        state_dict = checkpoint['model'] if isinstance(checkpoint, dict) and 'model' in checkpoint else checkpoint
        model.load_state_dict(state_dict)
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None

    model = model.to(DEVICE)
    model.eval()
    return model, class_names


def predict_local(image, model, class_names):
    preprocess = transforms.Compose([
        transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    input_tensor = preprocess(image).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        outputs = model(input_tensor)
        probs = torch.nn.functional.softmax(outputs, dim=1)[0]
        top_p, top_idx = probs.topk(1)
    return class_names[top_idx.item()], top_p.item() * 100


def ask_deepseek_stream(latin_name, location, season):
    if not API_KEY:
        yield "âš ï¸ API Key ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"
        return

    client = OpenAI(api_key=API_KEY, base_url="https://api.deepseek.com")

    # ğŸ”¥ ä¼˜åŒ– Promptï¼šå¼ºåˆ¶ Markdown æ ¼å¼ï¼Œé˜²æ­¢ç¼©è¿›å¯¼è‡´æ¸²æŸ“å¤±è´¥
    prompt = f"""
    ä½ æ˜¯ä¸€ä½æ¤ç‰©ç§‘æ™®ä¸“å®¶ã€‚è¯·ç”Ÿæˆå…³äº"{latin_name}"çš„ç§‘æ™®æŠ¥å‘Šã€‚
    è§‚å¯Ÿä¿¡æ¯ï¼šåœ°ç‚¹-{location}ï¼Œå­£èŠ‚-{season}ã€‚

    ã€æ ¼å¼è¦æ±‚ã€‘
    1. å¿…é¡»ä½¿ç”¨æ ‡å‡†çš„ Markdown æ ¼å¼ã€‚
    2. ä¸è¦ä½¿ç”¨ä»£ç å—ã€‚
    3. æ ‡é¢˜å‰ä¸è¦æœ‰ç©ºæ ¼ç¼©è¿›ã€‚

    ã€å†…å®¹å¤§çº²ã€‘
    ## ä¸­æ–‡æ­£åä¸ç§‘å±
    ï¼ˆè¿™é‡Œä»‹ç»ä¸­æ–‡åã€åˆ«åã€ç§‘å±ï¼‰

    ## å½¢æ€ç‰¹å¾
    ï¼ˆç®€è¦æè¿°èŠ±ã€å¶ç‰¹å¾ï¼‰

    ## ç¯å¢ƒä¸ä¹ æ€§
    ï¼ˆç»“åˆ{location}å’Œ{season}åˆ†æï¼‰

    ## è¶£å‘³å†·çŸ¥è¯†
    ï¼ˆä¸€ä¸ªæœ‰è¶£çš„çŸ¥è¯†ç‚¹ï¼‰
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            stream=True,
            temperature=1.3
        )
        for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:
        yield f"âŒ API Error: {e}"


# =========================================================
# ğŸ¨ 2. ç•Œé¢é€»è¾‘
# =========================================================
def main():
    st.markdown('<div class="main-title">ğŸŒ¿ AI æ¤ç‰©ç™¾ç§‘å…¨ä¹¦</div>', unsafe_allow_html=True)

    with st.sidebar:
        uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šä¼ ç…§ç‰‡", type=["jpg", "png", "jpeg"])
        location = st.text_input("ğŸ“ åœ°ç‚¹", value="å…¬å›­")
        season = st.selectbox("ğŸ—“ï¸ å­£èŠ‚", ["æ˜¥å­£", "å¤å­£", "ç§‹å­£", "å†¬å­£"])
        if API_KEY:
            st.success("âœ… DeepSeek API å·²è¿æ¥")
            if st.button("é‡ç½® Key"):
                if os.path.exists(KEY_FILE): os.remove(KEY_FILE)
                st.rerun()  # æ–°ç‰ˆ streamlit ä½¿ç”¨ rerun
        else:
            st.error("âŒ API æœªé…ç½®")

    if not uploaded_file: return

    with st.spinner("ğŸ§  æ­£åœ¨åˆ†æ..."):
        model, class_names = load_resources()
        if model:
            image = Image.open(uploaded_file).convert('RGB')
            col1, col2 = st.columns([1, 1.2])

            with col1:
                st.image(image, use_container_width=True)

            with col2:
                name, conf = predict_local(image, model, class_names)

                # ç»“æœå¡ç‰‡
                st.markdown(f"""
                <div class="result-card">
                    <div style="color: #666; font-size: 0.9em;">è¯†åˆ«ç»“æœ</div>
                    <div class="latin-name">{name}</div>
                    <div style="margin-top: 5px; color: {'#2E7D32' if conf > 80 else '#F9A825'}">
                        ç½®ä¿¡åº¦: {conf:.2f}%
                    </div>
                </div>
                """, unsafe_allow_html=True)

                if st.button("âœ¨ ç”Ÿæˆç§‘æ™®æŠ¥å‘Š", type="primary"):
                    st.markdown("---")
                    res_box = st.empty()
                    full_text = ""

                    # ä½¿ç”¨ div åŒ…è£¹ä»¥åº”ç”¨ CSS
                    st.markdown('<div class="report-container">', unsafe_allow_html=True)

                    for chunk in ask_deepseek_stream(name, location, season):
                        full_text += chunk
                        # å®æ—¶æ¸²æŸ“ï¼Œå¢åŠ  strip() é˜²æ­¢å¼€å¤´ç©ºæ ¼
                        res_box.markdown(full_text + " â–Œ", unsafe_allow_html=True)

                    # æœ€ç»ˆæ¸²æŸ“
                    res_box.markdown(full_text, unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)


if __name__ == "__main__":
    main()